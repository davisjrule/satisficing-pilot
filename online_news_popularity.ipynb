{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Dataset: Online News Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Online News Popularity dataset is a classification dataset: it is used for a prediction task where the goal is to determine whether an article posted on Mashable.com was popular or not, based on how many times it was shared online. \n",
    "#### The list of attributes is as follows:\n",
    "- output variable: **shares**, number of shares, <1400 and >=1400 (converted to 0 and 1 respectively)\n",
    "- input features:      \n",
    "    - **n_tokens_title**: Number of words in the title; continuous\n",
    "    - **n_tokens_content**: Number of words in the content; continuous\n",
    "    - **n_unique_tokens**: Rate of unique words in the content; continuous\n",
    "    - **n_non_stop_words**: Rate of non-stop words in the content; continuous\n",
    "    - **n_non_stop_unique_tokens**: Rate of unique non-stop words in the content; continuous                        \n",
    "    - **num_hrefs**: Number of links; continuous\n",
    "    - **num_self_hrefs**: Number of links to other articles published by Mashable; continuous\n",
    "    - **num_imgs**: Number of images; continuous\n",
    "    - **num_videos**: Number of videos; continuous\n",
    "    - **average_token_length**: Average length of the words in the content; continuous\n",
    "    - **num_keywords**: Number of keywords in the metadata; continuous\n",
    "    - **data_channel**: Is data channel 'Lifestyle', 'Entertainment', 'Business', 'Social Media', 'Tech' ,'World'?; \n",
    "        categorical             \n",
    "    - **kw_min_min**: Worst keyword (min. shares); continuous\n",
    "    - **kw_max_min**: Worst keyword (max. shares); continuous\n",
    "    - **kw_avg_min**: Worst keyword (avg. shares); continuous\n",
    "    - **kw_min_max**: Best keyword (min. shares); continuous\n",
    "    - **kw_max_max**: Best keyword (max. shares); continuous\n",
    "    - **kw_avg_max**: Best keyword (avg. shares); continuous\n",
    "    - **kw_min_avg**: Average keyword (min. shares); continuous\n",
    "    - **kw_max_avg**: Average keyword (max. shares); continuous\n",
    "    - **kw_avg_avg**: Average keyword (avg. shares); continuous\n",
    "    - **self_reference_min_shares**: Min. shares of referenced articles on Mashable; continuous\n",
    "    - **self_reference_max_shares**: Max. shares of referenced articles on Mashable; continuous\n",
    "    - **self_reference_avg_shares**: Avg. shares of referenced articles on Mashable; continuous\n",
    "    - **day_of_week**: Which day of the week was the article published on? Mon-Sun; categorical\n",
    "    - **is_weekend**: Was the article published on the weekend?; binary\n",
    "    - **LDA_00**: Closeness to LDA topic 0; continuous\n",
    "    - **LDA_01**: Closeness to LDA topic 1; continuous\n",
    "    - **LDA_02**: Closeness to LDA topic 2; continuous\n",
    "    - **LDA_03**: Closeness to LDA topic 3; continuous\n",
    "    - **LDA_04**: Closeness to LDA topic 4; continuous\n",
    "    - **global_subjectivity**: Text subjectivity; continuous\n",
    "    - **global_sentiment_polarity**: Text sentiment polarity; continuous\n",
    "    - **global_rate_positive_words**: Rate of positive words in the content; continuous\n",
    "    - **global_rate_negative_words**: Rate of negative words in the content; continuous\n",
    "    - **rate_positive_words**: Rate of positive words among non-neutral tokens; continuous\n",
    "    - **rate_negative_words**: Rate of negative words among non-neutral tokens; continuous\n",
    "    - **avg_positive_polarity**: Avg. polarity of positive words; continuous\n",
    "    - **min_positive_polarity**:  Min. polarity of positive words; continuous\n",
    "    - **max_positive_polarity**: Max. polarity of positive words; continuous\n",
    "    - **avg_negative_polarity**: Avg. polarity of negative  words; continuous\n",
    "    - **min_negative_polarity**: Min. polarity of negative  words; continuous\n",
    "    - **max_negative_polarity**: Max. polarity of negative  words; continuous\n",
    "    - **title_subjectivity**:  Title subjectivity; continuous\n",
    "    - **title_sentiment_polarity**: Title polarity; continuous\n",
    "    - **abs_title_subjectivity**: Absolute subjectivity level; continuous\n",
    "    - **abs_title_sentiment_polarity**: Absolute polarity level; continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs  \\\n",
       "0                   0.815385         4.0              2.0        1.0   \n",
       "1                   0.791946         3.0              1.0        1.0   \n",
       "2                   0.663866         3.0              1.0        1.0   \n",
       "3                   0.665635         9.0              0.0        1.0   \n",
       "4                   0.540890        19.0             19.0       20.0   \n",
       "\n",
       "    num_videos   average_token_length  ...   avg_positive_polarity  \\\n",
       "0          0.0               4.680365  ...                0.378636   \n",
       "1          0.0               4.913725  ...                0.286915   \n",
       "2          0.0               4.393365  ...                0.495833   \n",
       "3          0.0               4.404896  ...                0.385965   \n",
       "4          0.0               4.682836  ...                0.411127   \n",
       "\n",
       "   min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0               0.100000                     0.7               -0.350000   \n",
       "1               0.033333                     0.7               -0.118750   \n",
       "2               0.100000                     1.0               -0.466667   \n",
       "3               0.136364                     0.8               -0.369697   \n",
       "4               0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity  \n",
       "0                       0.187500  \n",
       "1                       0.000000  \n",
       "2                       0.000000  \n",
       "3                       0.000000  \n",
       "4                       0.136364  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"online_news_popularity.csv\")\n",
    "\n",
    "cols = [' n_tokens_title', ' n_tokens_content',\n",
    "       ' n_unique_tokens', ' n_non_stop_words', ' n_non_stop_unique_tokens',\n",
    "       ' num_hrefs', ' num_self_hrefs', ' num_imgs', ' num_videos',\n",
    "       ' average_token_length', ' num_keywords',\n",
    "       'data_channel', ' kw_min_min', ' kw_max_min', ' kw_avg_min',\n",
    "       ' kw_min_max', ' kw_max_max', ' kw_avg_max', ' kw_min_avg',\n",
    "       ' kw_max_avg', ' kw_avg_avg', ' self_reference_min_shares',\n",
    "       ' self_reference_max_shares', ' self_reference_avg_sharess',\n",
    "       'day_of_week', ' is_weekend', ' LDA_00', ' LDA_01', ' LDA_02',\n",
    "       ' LDA_03', ' LDA_04', ' global_subjectivity',\n",
    "       ' global_sentiment_polarity', ' global_rate_positive_words',\n",
    "       ' global_rate_negative_words', ' rate_positive_words',\n",
    "       ' rate_negative_words', ' avg_positive_polarity',\n",
    "       ' min_positive_polarity', ' max_positive_polarity',\n",
    "       ' avg_negative_polarity', ' min_negative_polarity',\n",
    "       ' max_negative_polarity', ' title_subjectivity',\n",
    "       ' title_sentiment_polarity', ' abs_title_subjectivity',\n",
    "       ' abs_title_sentiment_polarity', ' shares']\n",
    "\n",
    "def get_day_of_week(row):\n",
    "    if row[' weekday_is_monday'] == 1:\n",
    "        return \"Monday\"\n",
    "    elif row[' weekday_is_tuesday'] == 1:\n",
    "        return \"Tuesday\"\n",
    "    elif row[' weekday_is_wednesday'] == 1:\n",
    "        return \"Wednesday\"\n",
    "    elif row[' weekday_is_thursday'] == 1:\n",
    "        return \"Thursday\"\n",
    "    elif row[' weekday_is_friday'] == 1:\n",
    "        return \"Friday\"\n",
    "    elif row[' weekday_is_saturday'] == 1:\n",
    "        return \"Saturday\"\n",
    "    else:\n",
    "        return \"Sunday\"\n",
    "    \n",
    "def get_channel(row):\n",
    "    if row[' data_channel_is_lifestyle'] == 1:\n",
    "        return \"Lifestyle\"\n",
    "    elif row[' data_channel_is_entertainment'] == 1:\n",
    "        return \"Entertainment\"\n",
    "    elif row[' data_channel_is_bus'] == 1:\n",
    "        return \"Business\"\n",
    "    elif row[' data_channel_is_socmed'] == 1:\n",
    "        return \"Social Media\"\n",
    "    elif row[' data_channel_is_tech'] == 1:\n",
    "        return \"Tech\"\n",
    "    else:\n",
    "        return \"World\"\n",
    "\n",
    "df['day_of_week'] = df.apply(lambda row: get_day_of_week(row), axis=1)\n",
    "df['data_channel'] = df.apply(lambda row: get_channel(row), axis=1)\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "train_cols = df.columns[0:-1]\n",
    "label = df.columns[-1]\n",
    "X_df = df[train_cols]\n",
    "y_df = df[label]\n",
    "\n",
    "# Converting the response / output variable to a binary class\n",
    "y_df = y_df.apply(lambda x: 0 if x < 1400 else 1)\n",
    "\n",
    "dataset = {\n",
    "        'X': X_df,\n",
    "        'y': y_df,\n",
    "}\n",
    "\n",
    "#Top 5 rows of the original dataset:\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for any data-related exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Model: GAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExplainableBoostingClassifier(feature_names=[' n_tokens_title',\n",
       "                                             ' n_tokens_content',\n",
       "                                             ' n_unique_tokens',\n",
       "                                             ' n_non_stop_words',\n",
       "                                             ' n_non_stop_unique_tokens',\n",
       "                                             ' num_hrefs', ' num_self_hrefs',\n",
       "                                             ' num_imgs', ' num_videos',\n",
       "                                             ' average_token_length',\n",
       "                                             ' num_keywords', 'data_channel',\n",
       "                                             ' kw_min_min', ' kw_max_min',\n",
       "                                             ' kw_avg_min', ' kw_min_max',\n",
       "                                             ' kw_max_max', ' kw_avg_max',\n",
       "                                             ' kw_min_avg', ' kw_max_...\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'categorical',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'categorical', 'categorical',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous', ...])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create a train/test split\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['X'],dataset['y'], test_size=0.25, random_state=seed)\n",
    "\n",
    "# train a GAM for the training dataset\n",
    "ebm = ExplainableBoostingClassifier()\n",
    "\n",
    "ebm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the training set is:  0.6855\n",
      "The accuracy of the model on the test set is:  0.66613\n"
     ]
    }
   ],
   "source": [
    "#Training accuracy\n",
    "train_pred = ebm.predict(X_train).tolist()\n",
    "accuracy_train = round(sum(train_pred == y_train) / len(train_pred), 5)\n",
    "\n",
    "# #Test set accuracy\n",
    "predictions = ebm.predict(X_test).tolist()\n",
    "accuracy_test = round(sum(predictions == y_test) / len(predictions), 5)\n",
    "\n",
    "print(\"The accuracy of the model on the training set is: \", accuracy_train)\n",
    "print(\"The accuracy of the model on the test set is: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Global Explanations: What the model learned overall from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/5008194816/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/5008194816/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret import show\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Local Explanations: How an individual prediction was made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/5132053952/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/5132053952/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebm_local = ebm.explain_local(X_test[:15], y_test[:15], name = 'EBM')\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Questions\n",
    "Please answer these to the best of your abilities. Make sure to also answer the follow-up questions in each of the code cells.\n",
    "\n",
    "If you need to write code to answer the question, please use the code cell provided\n",
    "\n",
    "If you don't know how to answer a question, please note that to the researcher in the room, explain why you cannot answer the question in the cell, and move on to the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Familiarity with the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How familiar are you with online news articles shared on Mashable.com? \n",
    "\n",
    "# If you had to give it a number, on a scale of 1-7 (where 1 = Not at all and 7 = Extremely),\n",
    "# How would you rate your familiarity? \n",
    "    # Response: \n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Have you previously interacted with datasets about online news popularity? \n",
    "\n",
    "# On a scale of 1-7, how would you rate your familiarity with datasets about online news popularity? \n",
    "    # Response: \n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Specifically, have you worked with UCI repository's Online News Popularity dataset based on Mashable articles?  \n",
    "\n",
    "# On a scale of 1-7, how would you rate your familiarity with the above UCI repository dataset on Online News Popularity?\n",
    "    # Response: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Global feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Is this feature importance order reasonable for online news popularity data? Why or why not?\n",
    "\n",
    "\n",
    "# Please answer the following on a scale of 1-7 (where 1 = Not at all and 7 = Extremely):\n",
    "# How reasonable is the feature importance order?\n",
    "    # Response: \n",
    "# How confident are you that you have understood the explanation correctly?\n",
    "    # Response: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Individual feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How would you describe the relationship between the feature \"data_channel\" and predicted popularity?\n",
    "\n",
    "\n",
    "## How would you describe the relationship between the feature \"data_channel\" and predicted popularity?\n",
    "\n",
    "\n",
    "## How would you describe the relationship between the feature \"data_channel\" and predicted popularity?\n",
    "\n",
    "\n",
    "# Please answer the following on a scale of 1-7 (where 1 = Not at all and 7 = Extremely):\n",
    "# How confident are you that these relationships are reasonable? \n",
    "    # Response: \n",
    "# How confident are you that you have understood these explanations correctly?\n",
    "    # Response: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: Local predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![online_news_popularity_hidden_result.png](online_news_popularity_hidden_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Given the above input feature values, do you think this article was popular (shared over 1400 times) or not? Why?\n",
    "\n",
    "\n",
    "# Please answer the following on a scale of 1-7 (where 1 = Not at all and 7 = Extremely):\n",
    "# How confident are you that your predicted answer is reasonable? \n",
    "    # Response: \n",
    "# How confident are you that you have understood the explanation correctly?\n",
    "    # Response: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5: Local misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/5303088752/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/5303088752/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebm_local = ebm.explain_local(X_test[229:230], y_test[229:230], name='EBM')\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The model misclassified this particular datapoint (above). Why do you think that happened?\n",
    "\n",
    "\n",
    "# Please answer the following on a scale of 1-7 (where 1 = Not at all and 7 = Extremely):\n",
    "# How confident are you that your response for the question above is reasonable? \n",
    "    # Response: \n",
    "# How confident are you that you have understood the explanation correctly?\n",
    "    # Response: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6: Reflecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On a scale of 1-7, how easy was it to answer these questions about online news popularity?\n",
    "\n",
    "## What made it easy/hard to answer questions about online news popularity?\n",
    "\n",
    "## When answering the questions, were you relying on the visuals alone or was there any prior knowledge you used in your answers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
